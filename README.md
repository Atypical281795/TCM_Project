# ä¸­é†«å•ç­”æ¨¡å‹è©•æ¸¬ç³»çµ± - å®‰è£è¨­ç½®æŒ‡å—

## ğŸ“‹ ç³»çµ±è¦æ±‚

- Python 3.8+
- Windows/Linux/macOS
- è‡³å°‘ 8GB RAMï¼ˆæ¨è–¦ 16GB+ï¼‰
- å¦‚æœä½¿ç”¨GPUæ¨ç†ï¼Œéœ€è¦CUDAç’°å¢ƒ

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. ç’°å¢ƒæº–å‚™

```bash
# å®‰è£cuda 12.1
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda-repo-ubuntu2004-12-1-local_12.1.0-530.30.02-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2004-12-1-local_12.1.0-530.30.02-1_amd64.deb
sudo cp /var/cuda-repo-ubuntu2004-12-1-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda


```bash
# å‰µå»ºè™›æ“¬ç’°å¢ƒï¼ˆæ¨è–¦ï¼‰
conda create -n tcm_eval python==3.9
conda activate tcm_eval

# æˆ–ä½¿ç”¨ venv
python -m venv tcm_eval
# Windows
tcm_eval\Scripts\activate
# Linux/macOS
source tcm_eval/bin/activate
```

### 2. å®‰è£ä¾è³´

```bash
# åŸºç¤ä¾è³´ï¼ˆå¿…é ˆï¼‰
pip install pandas numpy scipy matplotlib seaborn
# æ¨¡å‹æ¨ç†ä¾è³´ï¼ˆæ ¹æ“šä½ çš„æ¨¡å‹é¸æ“‡ï¼‰
# å¦‚æœä½¿ç”¨ Transformers + PyTorch
pip install accelerate protobuf sentencepiece
pip install torch==2.2.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121
pip install transformers==4.36.0
pip install markupsafe==2.1.3
pip install jinja2==3.1.2

# å¦‚æœä½¿ç”¨ Transformers + CPU ç‰ˆæœ¬
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# å¦‚æœä½¿ç”¨å…¶ä»–æ¡†æ¶ï¼Œè«‹å®‰è£ç›¸æ‡‰ä¾è³´
```

### 3. ä¸‹è¼‰è©•æ¸¬è…³æœ¬

å°‡ä»¥ä¸‹æ–‡ä»¶ä¿å­˜åˆ°åŒä¸€ç›®éŒ„ï¼š
- `tcm_evaluation.py` - ä¸»è©•æ¸¬ç³»çµ±
- `quick_evaluation.py` - å¿«é€Ÿè©•æ¸¬è…³æœ¬
- `tcm_exam_question.csv` - ä½ çš„ä¸­é†«å•ç­”è³‡æ–™é›†

### 4. é…ç½®è·¯å¾‘

ç·¨è¼¯ `quick_evaluation.py` ä¸­çš„è·¯å¾‘é…ç½®ï¼š

```python
# ä¿®æ”¹é€™äº›è·¯å¾‘ç‚ºä½ çš„å¯¦éš›è·¯å¾‘
MODEL_PATH = r"C:\Users\user\Desktop\LLaMA-Factory\Breeze_lindan TCPM QA"
DATASET_PATH = "tcm_exam_question.csv"
OUTPUT_DIR = "quick_evaluation_results"
SAMPLE_SIZE = 500  # å¿«é€Ÿæ¸¬è©¦ç”¨ï¼Œè¨­ç‚º None ä½¿ç”¨å…¨éƒ¨æ•¸æ“š
```

### 5. é‹è¡Œè©•æ¸¬

```bash
# å¿«é€Ÿè©•æ¸¬
python quick_evaluation.py

# æˆ–ä½¿ç”¨å‘½ä»¤è¡Œç‰ˆæœ¬ï¼ˆå®Œæ•´åŠŸèƒ½ï¼‰
python tcm_evaluation.py --model_path "ä½ çš„æ¨¡å‹è·¯å¾‘" --dataset_path "tcm_exam_question.csv" --generate_charts
```

## ğŸ“Š è©•æ¸¬æµç¨‹èªªæ˜

### ç¬¬ä¸€æ¬¡ä½¿ç”¨æµç¨‹

1. **æ¨¡å‹è¼‰å…¥**: ç³»çµ±æœƒè¼‰å…¥ä½ çš„å¾®èª¿æ¨¡å‹
2. **è³‡æ–™é›†æª¢æŸ¥**: è‡ªå‹•æª¢æŸ¥è³‡æ–™é›†æ ¼å¼å’Œå…§å®¹
3. **æ¨£æœ¬è©•æ¸¬**: å°é¸å®šæ•¸é‡çš„é¡Œç›®é€²è¡Œæ¨ç†
4. **æŒ‡æ¨™è¨ˆç®—**: è¨ˆç®—æº–ç¢ºç‡ã€ä¿¡å¿ƒåˆ†æ•¸ç­‰æŒ‡æ¨™
5. **çµæœä¿å­˜**: ç”ŸæˆCSVã€JSONã€åœ–è¡¨ç­‰å¤šç¨®æ ¼å¼çš„çµæœ

### è©•æ¸¬æŒ‡æ¨™èªªæ˜

- **æº–ç¢ºç‡**: æ¨¡å‹ç­”å°é¡Œç›®çš„ç™¾åˆ†æ¯”
- **ä¿¡å¿ƒåˆ†æ•¸**: æ¨¡å‹å°å…¶ç­”æ¡ˆçš„ç½®ä¿¡åº¦
- **å›æ‡‰æ™‚é–“**: æ¨¡å‹æ¨ç†æ¯é“é¡Œçš„å¹³å‡æ™‚é–“
- **åˆ†é¡åˆ¥åˆ†æ**: æŒ‰ä¸­é†«ç§‘ç›®åˆ†é¡çš„è¡¨ç¾
- **éŒ¯èª¤åˆ†æ**: è©³ç´°çš„éŒ¯èª¤æ¡ˆä¾‹åˆ†æ

## ğŸ”§ æ¨¡å‹é©é…

### æ”¯æ´çš„æ¨¡å‹æ ¼å¼

1. **Transformers æ ¼å¼** (æ¨è–¦)
   - Llama, Qwen, ChatGLM ç­‰
   - ä½¿ç”¨ AutoModelForCausalLM è¼‰å…¥

2. **è‡ªå®šç¾©æ ¼å¼**
   - ä¿®æ”¹ `get_model_answer()` æ–¹æ³•
   - å¯¦ç¾ä½ çš„æ¨ç†é‚è¼¯

### æ¨¡å‹é©é…ç¯„ä¾‹

å¦‚æœä½ çš„æ¨¡å‹éœ€è¦ç‰¹æ®Šè¼‰å…¥æ–¹å¼ï¼Œä¿®æ”¹ `load_model()` æ–¹æ³•ï¼š

```python
def load_model(self):
    """è‡ªå®šç¾©æ¨¡å‹è¼‰å…¥"""
    try:
        # ä½ çš„è‡ªå®šç¾©è¼‰å…¥é‚è¼¯
        from your_model_library import YourModel
        
        self.model = YourModel.from_pretrained(self.model_path)
        self.tokenizer = YourTokenizer.from_pretrained(self.model_path)
        
        self.logger.info("è‡ªå®šç¾©æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        
    except Exception as e:
        self.logger.error(f"è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
        self.model = None
```

### æç¤ºè©å®¢è£½åŒ–

ä¿®æ”¹ `format_prompt()` æ–¹æ³•ä¾†èª¿æ•´æç¤ºè©æ ¼å¼ï¼š

```python
def format_prompt(self, question: str) -> str:
    """å®¢è£½åŒ–æç¤ºè©"""
    # ç¯„ä¾‹ï¼šåŠ å…¥è§’è‰²è¨­å®šå’Œç‰¹æ®Šæ ¼å¼
    prompt = f"""<|system|>
ä½ æ˜¯ä¸€ä½è³‡æ·±çš„ä¸­é†«å¸«ï¼Œå…·æœ‰è±å¯Œçš„è‡¨åºŠç¶“é©—å’Œæ·±åšçš„ç†è«–åŸºç¤ã€‚

<|user|>
è«‹æ ¹æ“šä»¥ä¸‹ä¸­é†«å•é¡Œé¸æ“‡æ­£ç¢ºç­”æ¡ˆï¼Œåªéœ€å›ç­”é¸é …å­—æ¯ï¼ˆAã€Bã€Cæˆ–Dï¼‰ï¼š

{question}

<|assistant|>
"""
    return prompt
```

## ğŸ› ï¸ é€²éšåŠŸèƒ½

### 1. æ‰¹é‡æ¨¡å‹æ¯”è¼ƒ

```python
from tcm_evaluation import BatchEvaluator

# æº–å‚™å¤šå€‹æ¨¡å‹è·¯å¾‘
models = [
    ("baseline", "path/to/baseline/model"),
    ("fine_tuned", "path/to/fine_tuned/model"),
    ("ensemble", "path/to/ensemble/model")
]

# æ‰¹é‡è©•æ¸¬
batch_evaluator = BatchEvaluator("tcm_exam_question.csv")
results = batch_evaluator.evaluate_multiple_models(
    model_paths=[path for _, path in models],
    model_names=[name for name, _ in models],
    sample_size=1000
)
```

### 2. è‡ªå®šç¾©è©•æ¸¬æŒ‡æ¨™

```python
def calculate_custom_metrics(self, results):
    """è‡ªå®šç¾©è©•æ¸¬æŒ‡æ¨™"""
    # è¨ˆç®— F1 åˆ†æ•¸ï¼ˆå¤šåˆ†é¡ï¼‰
    from sklearn.metrics import classification_report
    
    y_true = [r.correct_answer for r in results]
    y_pred = [r.model_answer for r in results]
    
    report = classification_report(y_true, y_pred, output_dict=True)
    
    # è¨ˆç®—å„é¸é …çš„æº–ç¢ºç‡
    option_accuracy = {}
    for option in ['A', 'B', 'C', 'D']:
        option_results = [r for r in results if r.correct_answer == option]
        if option_results:
            correct = sum(1 for r in option_results if r.is_correct)
            option_accuracy[f'option_{option}'] = correct / len(option_results)
    
    return {
        'classification_report': report,
        'option_accuracy': option_accuracy
    }
```

### 3. éŒ¯èª¤åˆ†æå¢å¼·

```python
def analyze_errors(self, results):
    """è©³ç´°éŒ¯èª¤åˆ†æ"""
    incorrect_results = [r for r in results if not r.is_correct]
    
    # æŒ‰éŒ¯èª¤é¡å‹åˆ†é¡
    error_patterns = {
        'A_to_B': 0, 'A_to_C': 0, 'A_to_D': 0,
        'B_to_A': 0, 'B_to_C': 0, 'B_to_D': 0,
        # ... å…¶ä»–çµ„åˆ
    }
    
    for result in incorrect_results:
        pattern = f"{result.correct_answer}_to_{result.model_answer}"
        if pattern in error_patterns:
            error_patterns[pattern] += 1
    
    # æ‰¾å‡ºé«˜é »éŒ¯èª¤æ¨¡å¼
    frequent_errors = sorted(
        error_patterns.items(), 
        key=lambda x: x[1], 
        reverse=True
    )[:5]
    
    return {
        'total_errors': len(incorrect_results),
        'error_patterns': error_patterns,
        'frequent_errors': frequent_errors
    }
```

## ğŸ“ˆ çµæœè§£è®€æŒ‡å—

### æº–ç¢ºç‡æ¨™æº–

- **90%+**: å„ªç§€ï¼Œæ¥è¿‘å°ˆæ¥­æ°´å¹³
- **80-90%**: è‰¯å¥½ï¼Œå…·å‚™åŸºæœ¬ä¸­é†«çŸ¥è­˜
- **70-80%**: ä¸­ç­‰ï¼Œéœ€è¦é€²ä¸€æ­¥æ”¹é€²
- **<70%**: è¼ƒå·®ï¼Œå»ºè­°é‡æ–°è¨“ç·´

### ä¿¡å¿ƒåˆ†æ•¸åˆ†æ

- **é«˜ä¿¡å¿ƒ+æ­£ç¢º**: æ¨¡å‹è¡¨ç¾æœ€ä½³
- **é«˜ä¿¡å¿ƒ+éŒ¯èª¤**: éœ€è¦é—œæ³¨çš„éåº¦è‡ªä¿¡æ¡ˆä¾‹
- **ä½ä¿¡å¿ƒ+æ­£ç¢º**: æ½›åœ¨çš„çŸ¥è­˜ç›²é»
- **ä½ä¿¡å¿ƒ+éŒ¯èª¤**: æ¨¡å‹ä¸ç¢ºå®šçš„é ˜åŸŸ

### tæª¢å®šçµæœè§£è®€

- **p < 0.05**: çµ±è¨ˆé¡¯è‘—å·®ç•°
- **Cohen's d**:
  - 0.2: å°æ•ˆæ‡‰
  - 0.5: ä¸­ç­‰æ•ˆæ‡‰
  - 0.8: å¤§æ•ˆæ‡‰

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **ModuleNotFoundError: No module named 'transformers'**
   ```bash
   pip install transformers torch
   ```

2. **CUDA out of memory**
   ```python
   # æ¸›å°‘batch_sizeæˆ–ä½¿ç”¨CPU
   torch_dtype=torch.float16  # ä½¿ç”¨åŠç²¾åº¦
   device_map="cpu"  # å¼·åˆ¶ä½¿ç”¨CPU
   ```

3. **æ¨¡å‹è¼‰å…¥å¤±æ•—**
   ```python
   # æª¢æŸ¥æ¨¡å‹è·¯å¾‘å’Œæ¬Šé™
   # ç¢ºä¿æ¨¡å‹æ–‡ä»¶å®Œæ•´
   # æª¢æŸ¥Pythonç‰ˆæœ¬ç›¸å®¹æ€§
   ```

4. **è©•æ¸¬é€Ÿåº¦æ…¢**
   ```python
   # ä½¿ç”¨è¼ƒå°æ¨£æœ¬
   SAMPLE_SIZE = 100
   
   # ä½¿ç”¨GPUåŠ é€Ÿ
   device_map="auto"
   
   # æ¸›å°‘max_new_tokens
   max_new_tokens=5
   ```

### èª¿è©¦æ¨¡å¼

å•Ÿç”¨è©³ç´°æ—¥èªŒï¼š

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### æ•ˆèƒ½å„ªåŒ–

1. **GPUè¨˜æ†¶é«”å„ªåŒ–**
   ```python
   # ä½¿ç”¨gradient checkpointing
   model.gradient_checkpointing_enable()
   
   # æ¸…ç†ç·©å­˜
   torch.cuda.empty_cache()
   ```

2. **æ¨ç†åŠ é€Ÿ**
   ```python
   # ä½¿ç”¨compiledæ¨¡å‹ (PyTorch 2.0+)
   model = torch.compile(model)
   
   # ä½¿ç”¨TensorRTæˆ–ONNX
   # æ‰¹é‡æ¨ç†
   ```

## ğŸ“ è¼¸å‡ºæ–‡ä»¶èªªæ˜

### æ–‡ä»¶çµæ§‹
```
evaluation_results/
â”œâ”€â”€ detailed_results_20241205_143022.csv     # è©³ç´°çµæœ
â”œâ”€â”€ evaluation_report_20241205_143022.json   # JSONå ±å‘Š
â”œâ”€â”€ summary_report_20241205_143022.txt       # æ–‡å­—ç¸½çµ
â”œâ”€â”€ evaluation_charts.png                    # è¦–è¦ºåŒ–åœ–è¡¨
â””â”€â”€ evaluation_20241205_143022.log          # é‹è¡Œæ—¥èªŒ
```

### CSVæ–‡ä»¶æ¬„ä½èªªæ˜

- `question_id`: é¡Œç›®ç·¨è™Ÿ
- `question`: é¡Œç›®å…§å®¹
- `correct_answer`: æ­£ç¢ºç­”æ¡ˆ
- `model_answer`: æ¨¡å‹ç­”æ¡ˆ
- `is_correct`: æ˜¯å¦æ­£ç¢º
- `confidence_score`: ä¿¡å¿ƒåˆ†æ•¸
- `response_time`: å›æ‡‰æ™‚é–“
- `category`: é¡Œç›®é¡åˆ¥

## ğŸ¯ æœ€ä½³å¯¦è¸

### è©•æ¸¬ç­–ç•¥

1. **åˆ†éšæ®µè©•æ¸¬**
   - å…ˆç”¨å°æ¨£æœ¬å¿«é€Ÿæ¸¬è©¦
   - ç¢ºèªç„¡èª¤å¾Œé€²è¡Œå…¨é‡è©•æ¸¬
   - å®šæœŸé‡æ–°è©•æ¸¬è¿½è¹¤é€²æ­¥

2. **å¤šç¶­åº¦åˆ†æ**
   - æ•´é«”æº–ç¢ºç‡
   - åˆ†é¡åˆ¥è¡¨ç¾
   - éŒ¯èª¤æ¨¡å¼åˆ†æ
   - ä¿¡å¿ƒæ ¡æº–

3. **çµæœé©—è­‰**
   - äººå·¥æª¢æŸ¥éƒ¨åˆ†çµæœ
   - äº¤å‰é©—è­‰
   - èˆ‡å°ˆå®¶è©•ä¼°å°æ¯”

### å ±å‘Šæ’°å¯«

1. **åŸ·è¡Œæ‘˜è¦**: é—œéµæŒ‡æ¨™å’Œçµè«–
2. **æ–¹æ³•æè¿°**: è©•æ¸¬è¨­ç½®å’Œåƒæ•¸
3. **çµæœåˆ†æ**: è©³ç´°æ•¸æ“šå’Œåœ–è¡¨
4. **æ”¹é€²å»ºè­°**: åŸºæ–¼çµæœçš„å„ªåŒ–æ–¹å‘

## ğŸš€ ä¸‹ä¸€æ­¥

1. é‹è¡Œå¿«é€Ÿè©•æ¸¬ç¢ºèªç³»çµ±æ­£å¸¸
2. èª¿æ•´æ¨£æœ¬å¤§å°é€²è¡Œå…¨é¢è©•æ¸¬
3. åˆ†æçµæœä¸¦è­˜åˆ¥æ”¹é€²é»
4. å¦‚æœ‰å¤šå€‹æ¨¡å‹ç‰ˆæœ¬ï¼Œé€²è¡Œæ¯”è¼ƒåˆ†æ
5. æ ¹æ“šçµæœèª¿æ•´è¨“ç·´ç­–ç•¥

## ğŸ’¡ æç¤º

- é¦–æ¬¡é‹è¡Œå»ºè­°ä½¿ç”¨å°æ¨£æœ¬ï¼ˆ100-500é¡Œï¼‰
- è¨˜éŒ„æ¯æ¬¡è©•æ¸¬çš„è¨­ç½®å’Œçµæœ
- å®šæœŸå‚™ä»½è©•æ¸¬çµæœ
- å»ºç«‹è©•æ¸¬åŸºæº–ç·šç”¨æ–¼å¾ŒçºŒæ¯”è¼ƒ

---

æœ‰ä»»ä½•å•é¡Œè«‹æŸ¥çœ‹æ—¥èªŒæ–‡ä»¶æˆ–è¯ç¹«æŠ€è¡“æ”¯æ´ï¼